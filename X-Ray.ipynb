{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONVOLUTIONAL NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project- Write an algorithm for a Bone X-Ray detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 99)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image, ImageFilter, ImageEnhance, ImageOps\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, cohen_kappa_score\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "import random\n",
    "random.seed(2048)\n",
    "seed(2048)\n",
    "set_random_seed(2048)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, LeakyReLU\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import regularizers\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset\n",
    "In the code cell below we import a csv file of training data and validation data \n",
    "\n",
    "- `train_image_paths.csv`\n",
    "- `train_labeled_studies.csv`\n",
    "- `valid_image_paths.csv`\n",
    "- `valid_labeled_studies.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset's CSVs\n",
    "train_image_paths = pd.read_csv('MURA-v1.1/train_image_paths.csv', names=['filepath'])\n",
    "train_labeled_studies = pd.read_csv('MURA-v1.1/train_labeled_studies.csv', dtype={1: str}, names=['path','class'])\n",
    "valid_image_paths = pd.read_csv('MURA-v1.1/valid_image_paths.csv', names=['filepath'])\n",
    "valid_labeled_studies = pd.read_csv('MURA-v1.1/valid_labeled_studies.csv', dtype={1: str}, names=['path','class'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Manipulating the dataframes and merging validation data to the testing data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>case</th>\n",
       "      <th>patient</th>\n",
       "      <th>patient_folder</th>\n",
       "      <th>patient_file</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image1.png</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00001</td>\n",
       "      <td>study1_positive</td>\n",
       "      <td>image1.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image2.png</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00001</td>\n",
       "      <td>study1_positive</td>\n",
       "      <td>image2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image3.png</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00001</td>\n",
       "      <td>study1_positive</td>\n",
       "      <td>image3.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image1.png</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00002</td>\n",
       "      <td>study1_positive</td>\n",
       "      <td>image1.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image2.png</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00002</td>\n",
       "      <td>study1_positive</td>\n",
       "      <td>image2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image3.png</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00002</td>\n",
       "      <td>study1_positive</td>\n",
       "      <td>image3.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00003/study1_positive/image1.png</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00003</td>\n",
       "      <td>study1_positive</td>\n",
       "      <td>image1.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00003/study1_positive/image2.png</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00003</td>\n",
       "      <td>study1_positive</td>\n",
       "      <td>image2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00003/study1_positive/image3.png</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00003</td>\n",
       "      <td>study1_positive</td>\n",
       "      <td>image3.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00004/study1_positive/image1.png</td>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>patient00004</td>\n",
       "      <td>study1_positive</td>\n",
       "      <td>image1.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              filepath  \\\n",
       "0  MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image1.png   \n",
       "1  MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image2.png   \n",
       "2  MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image3.png   \n",
       "3  MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image1.png   \n",
       "4  MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image2.png   \n",
       "5  MURA-v1.1/train/XR_SHOULDER/patient00002/study1_positive/image3.png   \n",
       "6  MURA-v1.1/train/XR_SHOULDER/patient00003/study1_positive/image1.png   \n",
       "7  MURA-v1.1/train/XR_SHOULDER/patient00003/study1_positive/image2.png   \n",
       "8  MURA-v1.1/train/XR_SHOULDER/patient00003/study1_positive/image3.png   \n",
       "9  MURA-v1.1/train/XR_SHOULDER/patient00004/study1_positive/image1.png   \n",
       "\n",
       "          case       patient   patient_folder patient_file class  \n",
       "0  XR_SHOULDER  patient00001  study1_positive   image1.png     1  \n",
       "1  XR_SHOULDER  patient00001  study1_positive   image2.png     1  \n",
       "2  XR_SHOULDER  patient00001  study1_positive   image3.png     1  \n",
       "3  XR_SHOULDER  patient00002  study1_positive   image1.png     1  \n",
       "4  XR_SHOULDER  patient00002  study1_positive   image2.png     1  \n",
       "5  XR_SHOULDER  patient00002  study1_positive   image3.png     1  \n",
       "6  XR_SHOULDER  patient00003  study1_positive   image1.png     1  \n",
       "7  XR_SHOULDER  patient00003  study1_positive   image2.png     1  \n",
       "8  XR_SHOULDER  patient00003  study1_positive   image3.png     1  \n",
       "9  XR_SHOULDER  patient00004  study1_positive   image1.png     1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Manipulating the dataframes\n",
    "train_image_paths['case'] = train_image_paths['filepath'].apply(lambda x: x.split('/')[2])\n",
    "train_image_paths['patient'] = train_image_paths['filepath'].apply(lambda x: x.split('/')[3])\n",
    "train_image_paths['patient_folder'] = train_image_paths['filepath'].apply(lambda x: x.split('/')[4])\n",
    "train_image_paths['patient_file'] = train_image_paths['filepath'].apply(lambda x: x.split('/')[5])\n",
    "train_image_paths['merge_path'] = train_image_paths['filepath'].apply(lambda x: x.rpartition('/')[0]+'/')\n",
    "train_data_df = train_image_paths.merge(train_labeled_studies, how='inner', left_on='merge_path', right_on='path').drop(columns=['merge_path', 'path'])\n",
    "\n",
    "valid_image_paths['case'] = valid_image_paths['filepath'].apply(lambda x: x.split('/')[2])\n",
    "valid_image_paths['patient'] = valid_image_paths['filepath'].apply(lambda x: x.split('/')[3])\n",
    "valid_image_paths['patient_folder'] = valid_image_paths['filepath'].apply(lambda x: x.split('/')[4])\n",
    "valid_image_paths['patient_file'] = valid_image_paths['filepath'].apply(lambda x: x.split('/')[5])\n",
    "valid_image_paths['merge_path'] = valid_image_paths['filepath'].apply(lambda x: x.rpartition('/')[0]+'/')\n",
    "test_data_df = valid_image_paths.merge(valid_labeled_studies, how='inner', left_on='merge_path', right_on='path').drop(columns=['merge_path', 'path'])\n",
    "\n",
    "train_data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XR_SHOULDER, XR_HUMERUS, XR_FINGER, XR_ELBOW, XR_WRIST, XR_FOREARM, XR_HAND\n",
    "# xr_train_df = train_data_df[train_data_df.case=='XR_WRIST']\n",
    "# xr_test_df = test_data_df[test_data_df.case=='XR_WRIST']\n",
    "# Copy the training and testing dataframe into new variables\n",
    "\n",
    "xr_train_df = train_data_df\n",
    "xr_test_df = test_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_train_df = xr_train_df.sample(frac = 1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the functions for processing the images before producing the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_size = 256\n",
    "\n",
    "# Function for making an image square, enhancing contrast and applying SHARPEN filter\n",
    "def make_square(im, min_size = 256, fill_color =0):\n",
    "    x, y = im.size\n",
    "    size = max(min_size, x, y)\n",
    "    new_im = Image.new('L', (size, size), fill_color)\n",
    "    new_im.paste(im, (int((size - x) / 2), int((size - y) / 2)))\n",
    "    enhancer = ImageEnhance.Contrast(new_im)\n",
    "    enhanced_im = enhancer.enhance(1.1)\n",
    "    return enhanced_im.filter(ImageFilter.SHARPEN)\n",
    "\n",
    "# invert an image\n",
    "def invert_image(im):\n",
    "    return ImageOps.invert(im)\n",
    "\n",
    "def make_dataset(dataframe_var, test = False):\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    patient_nr_y = []\n",
    "    \n",
    "    \n",
    "    # Make each image square and of size 256x256\n",
    "    for index, row in dataframe_var.iterrows():\n",
    "        im = Image.open(row['filepath']).convert('L')\n",
    "        squared = make_square(im)\n",
    "        resized = squared.resize((pic_size, pic_size))\n",
    "        \n",
    "        # For the training set only, augment the data by applying random rotations and inversions (negative)\n",
    "        \n",
    "        if test == False: \n",
    "            rotated_r = resized.rotate(random.randint(10,30))\n",
    "            if index%2: \n",
    "                rotated_r = invert_image(rotated_r)\n",
    "            numpy_rotated_r_pic = np.array(rotated_r)/255\n",
    "            train_x.append(numpy_rotated_r_pic)\n",
    "            train_y.append(row['class'])\n",
    "                \n",
    "            rotated_1 = resized.rotate(random.randint(330, 350))\n",
    "            if not index%2: \n",
    "                rotated_1 = invert_image(rotated_1)\n",
    "            numpy_rotated_r_pic = np.array(rotated_1)/255\n",
    "            train_x.append(numpy_rotated_r_pic)\n",
    "            train_y.append(row['class'])\n",
    "            \n",
    "        numpy_pic = np.array(resized)/255\n",
    "        train_x.append(numpy_pic)\n",
    "        train_y.append(row['class'])\n",
    "        if test: patient_nr_y.append(row['patient'][7:]+'_'+row['patient_folder'])\n",
    "            \n",
    "    return train_x, train_y, patient_nr_y\n",
    "\n",
    "                    \n",
    "                \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_train_x, xr_train_y, blank = make_dataset(xr_train_df)\n",
    "xr_train_x = np.asarray(xr_train_x)\n",
    "xr_train_y = np.asarray(xr_train_y)\n",
    "\n",
    "xr_test_x, xr_test_y, xr_patient = make_dataset(xr_test_df, test = True)\n",
    "xr_test_x = np.asarray(xr_test_x)\n",
    "xr_test_y = np.asarray(xr_test_y)\n",
    "xr_patient_y = np.asarray(xr_patient_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(xr_train_x[24332])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
